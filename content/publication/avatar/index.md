---
# Documentation: https://wowchemy.com/docs/managing-content/

title: 'AvatAR: An Immersive Analysis Environment for Human Motion Data Combining
  Interactive 3D Avatars and Trajectories'
subtitle: ''
summary: ''
authors:
- Patrick Reipschläger
- Frederik Brudy
- Raimund Dachselt
- Justin Matejka
- George Fitzmaurice
- Fraser Anderson
tags:
- human motion data
- motion analysis
- Immersive Analytics
- In-situ visualisation
- augmented/mixed reality
- analysing space utilization
categories: []
date: '2022-01-01'
lastmod: 2023-02-14T14:24:45-05:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2023-02-14T19:24:45.093408Z'
publication_types:
- '1'
abstract: Analysis of human motion data can reveal valuable insights about the utilization
  of space and interaction of humans with their environment. To support this, we present
  AvatAR, an immersive analysis environment for the in-situ visualization of human
  motion data, that combines 3D trajectories with virtual avatars showing people’s
  detailed movement and posture. Additionally, we describe how visualizations can
  be embedded directly into the environment, showing what a person looked at or what
  surfaces they touched, and how the avatar’s body parts can be used to access and
  manipulate those visualizations. AvatAR combines an AR HMD with a tablet to provide
  both mid-air and touch interaction for system control, as well as an additional
  overview device to help users navigate the environment. We implemented a prototype
  and present several scenarios to show that AvatAR can enhance the analysis of human
  motion data by making data not only explorable, but experienceable.
publication: '*Proceedings of the 2022 CHI Conference on Human Factors in Computing
  Systems*'
doi: 10.1145/3491102.3517676
links:
- name: URL
  url: https://doi.org/10.1145/3491102.3517676
---
