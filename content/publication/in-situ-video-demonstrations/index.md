---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Investigating the Feasibility of Extracting Tool Demonstrations from In-Situ
  Video Content
subtitle: ''
summary: ''
authors:
- Ben Lafreniere
- Tovi Grossman
- Justin Matejka
- George Fitzmaurice
tags:
- help
- toolclips
- in-situ usage data
- feature-rich software
- video tooltips
- learning
categories: []
date: '2014-01-01'
lastmod: 2023-02-14T14:24:46-05:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2023-02-14T19:24:46.648702Z'
publication_types:
- '1'
abstract: Short video demonstrations are effective resources for helping users to
  learn tools in feature-rich software. However manually creating demonstrations for
  the hundreds (or thousands) of individual features in these programs would be impractical.
  In this paper, we investigate the potential for identifying good tool demonstrations
  from within screen recordings of users performing real-world tasks. Using an instrumented
  image-editing application, we collected workflow video content and log data from
  actual end users. We then developed a heuristic for identifying demonstration clips,
  and had the quality of a sample set of clips evaluated by both domain experts and
  end users. This multi-step approach allowed us to characterize the quality of 'naturally
  occurring' tool demonstrations, and to derive a list of good and bad features of
  these videos. Finally, we conducted an initial investigation into using machine
  learning techniques to distinguish between good and bad demonstrations.
publication: '*Proceedings of the SIGCHI Conference on Human Factors in Computing
  Systems*'
doi: 10.1145/2556288.2557142
links:
- name: URL
  url: https://doi.org/10.1145/2556288.2557142
---
